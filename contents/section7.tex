\section{まとめ}
\label{sec:summary}
本書では, adversarial examples の基礎と具体的な攻撃手法や防御手法を解説し, それらを分類する際の観点を提示した.
ベースラインとなる攻撃手法といくつかの防御手法に対しては実証実験も実施し, 現状の攻撃手法と防御手法を概観した.

adversarial examples は DNN モデルを誤認識させる現象として興味深い研究対象であり, DNN を含むシステムを運用する立場からはシステムが誤認識によって期待しない振る舞いをさせる原因となり得る危険な対象でもある.
特に, 自動運転における動画像認識のように誤認識によって大きな事故に繋がりかねないようなシステムにとっては看過できない問題である.
現時点では adversarial examples は研究対象としての側面が強く, 実社会で組織だった攻撃が展開されている事例や防御方法を実際のサービスに導入しているという事例は表立っては聞かない\footnote{
ただし, 例えば Google Cloud Vision models には以前は成功していた攻撃が内部アルゴリズムの変更によって失敗するようになったという報告もある: \href{https://github.com/cg563/simple-blackbox-attack}{https://github.com/cg563/simple-blackbox-attack}.
大きな会社では内部で導入を進めていると考えるのが自然であろう.
}.
この段階から研究をキャッチアップして実証実験を実施し知見を蓄えておくことは, 近い将来に DNN を含むシステムを大規模に運用する人々にとって重要であることは疑うべくもない.

本書では攻撃方法と防御方法に関して, それぞれ 2019 年末の段階で主要なものを取り上げて解説した.
個別の手法の解説に留まらず, 先行研究を踏まえつつ独自の観点での分類も実施した.
攻撃方法の観点としては以下のものを採用した.
これは先行研究に基づきつつ実用を見据えて特に重要となる観点に着目したものである.
%
\begin{itemize}
  \item Digital (Pixel) attack $\lor$ Physical attack
  \item Classifier $\lor$ Detector
  \item 摂動作成時に使用するデータ
  \item 画像全体への摂動 $\lor$ 対象物のみへの摂動
  \item 知覚しづらさの定義
  \item White box $\lor$ Black box
\end{itemize}
%
防御方法の観点としては以下のものを採用した.
これはあまり先行研究では述べられていない対応コストという観点を入れており, こちらも実用を見据えての項目である.
%
\begin{itemize}
  \item 基本戦略 (正則化, 入力データ変更, 予測モデル変更, 外部モデル使用)
  \item 使用する外部リソース
  \item 対応コスト (人的コスト, 推論コスト)
\end{itemize}
%
図 \ref{fig:attack-summary} で攻撃手法を Digital (Pixel) attack $\lor$ Physical attack と White box $\lor$ Black box の 2 軸で分類し, 使用目的を概観した.
現実的な攻撃は black box であり digital は API への攻撃で physical は物理環境で稼働するシステムへの攻撃となり, white box は最悪ケースの想定とモデル理解や防御手法のために使われる.
図 \ref{fig:defense-process} では防御手法をモデル設計から予測結果使用までの一連のプロセスのどの部分に属するかでマッピングし, 特徴や導入のコストを概観した.
基本的にはプロセスの早い段階に位置するほど人的なコストは大きくなるが, 推論速度への影響も重要となることを考慮して目的に適った手法を選択する必要がある.

\ref{sec:attacks} 章では攻撃手法のいくつかをピックアップして解説した.
digital attack ではモデルを誤認識されるのは容易であることが分かっているため, 数ピクセルで攻撃したり画像を生成したりという難易度が難しめの手法が開発されたり, モデルに依存しない普遍的な摂動やあるモデルに対する摂動が他のモデルにも有効になる transferability などが盛んに調べられている.
現実的な攻撃手法の実現可能性を模索する physical attack の研究も増えてきている.
対象物にのみ摂動を加えるような工夫やカメラレンズに設置する摂動など多様な手法が提案されており, classifier だけでなく bbox や bbox 毎の予測に対して攻撃をすることで detector を誤認識させる手法も存在感が大きくなってきている.
実際の物理的環境では様々な物体があるため detector を運用することが多く, detector を対象とした研究はさらに重要性を増していくだろう.

\ref{sec:defenses} 章では防御手法のいくつかをピックアップして解説した.
基本となる adversarial training から始まり, 図 \ref{fig:defense-process} のプロセス毎に様々な手法が提案されている.
モデルをデプロイする前のプロセスに位置するものとしては, adversarial examples を学習データとして正則化を使う手法やモデルアーキテクチャに防御構造を組み込む手法などがある.
これらは一から学習する必要があるが, それが許容できれば推論時の速度への影響やその他システムへの影響は少ない.
モデルをデプロイした後のプロセスに位置するものとしては, 単純な仕組みや外部リソースを使って入力データを差し替える手法や clean データの分布と比較して adversarial examples を検出する手法などがある.
これらは元のモデルはそのまま使えるが, 他のシステムへの影響が大きかったり余分な計算資源が必要になったりする.
防御手法は個別の手法に注目して正答率をどう保つかを調べているものが多いが, 今度は実用を見据えたコストの観点や独立な防御手法を効果的に組み合わせて性能を高めるという観点も重視されていくだろう.

\ref{sec:exp} 章では FGSM 系の攻撃手法といくつかの防御手法を選び, PyTorch でフルスクラッチで実装をして検証を実施した.
一部うまく元論文の結果が再現できないものもあったが, 概ね元論文で主張されている性能を達成できることを確認し, 防御手法が実際に有効であることを示した.
adversarial training が基本的な防御手法となり, 他の手法と組み合わせることでさらに性能を高めることができる.
adversarial training は攻撃手法ありきの防御手法で想定していない攻撃にはあまり機能しない可能性があるが, どうしても防御は攻撃に合わせて発展していく必要があるため, 危険な攻撃手法が登場する度にそれを継続的に取り入れていくのが正着手であろう.
本書での実験は限定的であるため, より大きなデータや様々な手法を用いて多角的に検証をすることが必要となるが, そのための出発点となる結果が得られた.

adversarial examples は広く研究されている対象であり, 基礎研究の面でも応用の面でも様々な可能性を秘めている.
本書では, その一部として画像データに限って, さらに攻撃と防御という側面だけを切り出して解説した.
adversarial examples は攻撃と防御の両輪から成るもので, どちらの発展も重要である.
攻撃と防御, 二つの側面から adversarial examples を調べることで現象をより深く理解していくことができるだろう.
他領域との関連も興味深い点で, 本書でも取り上げたように domain adaptation との関連や, その他にも anomaly detection や interpretability などとも関連性が強い.

つらつらと書いていたら中々のページ数の本になってしまった.
これくらいの内容を扱えば「A Primer on Adversarial Examples」としてはよいのではないだろうかと思うが, 実際はどうだったかは読者が判断することなので, 感想があったら聞かせて欲しい.
より最新の動向を知りたい場合は, \href{https://www.slideshare.net/cvpaperchallenge/adversarial-examples-229232499}{https://www.slideshare.net/cvpaperchallenge/adversarial-examples-229232499} や ICML などのカンファレンスの論文を読んでいくのがよいだろう.
やる気があるなら, \href{https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html}{https://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html} で arXiv に投稿された adversarial examples に関する全論文をチェックしてもよい.
何か面白い論文があったらぜひ著者にも教えて欲しい.